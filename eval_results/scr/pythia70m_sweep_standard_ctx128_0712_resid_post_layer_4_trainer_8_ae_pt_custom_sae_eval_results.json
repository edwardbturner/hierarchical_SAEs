{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 125,
    "llm_batch_size": 512,
    "llm_dtype": "float32",
    "lower_vram_usage": false,
    "model_name": "pythia-70m-deduped",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "1ba1078c-4580-4a17-9e93-1b19534c8bf9",
  "datetime_epoch_millis": 1744378402915,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.2656937928571465,
      "scr_metric_threshold_2": 0.33229458098144604,
      "scr_dir2_threshold_2": 0.19494926953684802,
      "scr_dir1_threshold_5": 0.2518122808131031,
      "scr_metric_threshold_5": 0.3780311877147726,
      "scr_dir2_threshold_5": 0.29328942638614625,
      "scr_dir1_threshold_10": 0.25503309249833683,
      "scr_metric_threshold_10": 0.3913173785122238,
      "scr_dir2_threshold_10": 0.36111193858387286,
      "scr_dir1_threshold_20": 0.2693692825857048,
      "scr_metric_threshold_20": 0.4161886301824247,
      "scr_dir2_threshold_20": -0.03100030645355142,
      "scr_dir1_threshold_50": 0.3338304648158091,
      "scr_metric_threshold_50": 0.4402436087876855,
      "scr_dir2_threshold_50": -0.2725278288597606,
      "scr_dir1_threshold_100": 0.30647217192841736,
      "scr_metric_threshold_100": 0.4197164528270471,
      "scr_dir2_threshold_100": -0.334378095859815,
      "scr_dir1_threshold_500": 0.02080944823052546,
      "scr_metric_threshold_500": 0.1632295744461211,
      "scr_dir2_threshold_500": -1.2436873190270665
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.5851850690828767,
      "scr_metric_threshold_2": 0.5851850690828767,
      "scr_dir2_threshold_2": 0.19428558388535747,
      "scr_dir1_threshold_5": 0.5814814136188645,
      "scr_metric_threshold_5": 0.5814814136188645,
      "scr_dir2_threshold_5": 0.3542855566375217,
      "scr_dir1_threshold_10": 0.6037035671608479,
      "scr_metric_threshold_10": 0.6037035671608479,
      "scr_dir2_threshold_10": 0.4971428941220628,
      "scr_dir1_threshold_20": 0.5962962562328237,
      "scr_metric_threshold_20": 0.5962962562328237,
      "scr_dir2_threshold_20": -0.46857149474474397,
      "scr_dir1_threshold_50": 0.6740741247666313,
      "scr_metric_threshold_50": 0.6740741247666313,
      "scr_dir2_threshold_50": -0.18857137212948308,
      "scr_dir1_threshold_100": 0.5592592600768812,
      "scr_metric_threshold_100": 0.5592592600768812,
      "scr_dir2_threshold_100": -0.5771428804981449,
      "scr_dir1_threshold_500": 0.014814842613959097,
      "scr_metric_threshold_500": 0.014814842613959097,
      "scr_dir2_threshold_500": -1.3257144978581499
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.4791666703623909,
      "scr_metric_threshold_2": 0.4791666703623909,
      "scr_dir2_threshold_2": 0.28089913225058316,
      "scr_dir1_threshold_5": 0.5059523925675142,
      "scr_metric_threshold_5": 0.5059523925675142,
      "scr_dir2_threshold_5": 0.48314629316227925,
      "scr_dir1_threshold_10": 0.5178571777025427,
      "scr_metric_threshold_10": 0.5178571777025427,
      "scr_dir2_threshold_10": 0.6067414827350883,
      "scr_dir1_threshold_20": 0.5476190518427324,
      "scr_metric_threshold_20": 0.5476190518427324,
      "scr_dir2_threshold_20": 0.6966292586324558,
      "scr_dir1_threshold_50": 0.5982143443179126,
      "scr_metric_threshold_50": 0.5982143443179126,
      "scr_dir2_threshold_50": -1.6067408130203265,
      "scr_dir1_threshold_100": 0.5476190518427324,
      "scr_metric_threshold_100": 0.5476190518427324,
      "scr_dir2_threshold_100": -1.4943807582912363,
      "scr_dir1_threshold_500": 0.42261907401707777,
      "scr_metric_threshold_500": 0.42261907401707777,
      "scr_dir2_threshold_500": -4.123593180428523
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.5018587121718227,
      "scr_metric_threshold_2": 0.5018587121718227,
      "scr_dir2_threshold_2": 0.17682913532577565,
      "scr_dir1_threshold_5": 0.5501858933750433,
      "scr_metric_threshold_5": 0.5501858933750433,
      "scr_dir2_threshold_5": 0.2378050376090692,
      "scr_dir1_threshold_10": 0.5724906610155258,
      "scr_metric_threshold_10": 0.5724906610155258,
      "scr_dir2_threshold_10": 0.28658525061567225,
      "scr_dir1_threshold_20": 0.6208178422187464,
      "scr_metric_threshold_20": 0.6208178422187464,
      "scr_dir2_threshold_20": 0.2621949623909308,
      "scr_dir1_threshold_50": 0.5799255097028165,
      "scr_metric_threshold_50": 0.5799255097028165,
      "scr_dir2_threshold_50": -0.10975611528989658,
      "scr_dir1_threshold_100": 0.4535315309686021,
      "scr_metric_threshold_100": 0.4535315309686021,
      "scr_dir2_threshold_100": -0.31707302003587906,
      "scr_dir1_threshold_500": -0.3159852792034515,
      "scr_metric_threshold_500": -0.3159852792034515,
      "scr_dir2_threshold_500": -0.6036582706515513
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.5027472990828254,
      "scr_metric_threshold_2": 0.5027472990828254,
      "scr_dir2_threshold_2": 0.3181814076814149,
      "scr_dir1_threshold_5": 0.5549450810369309,
      "scr_metric_threshold_5": 0.5549450810369309,
      "scr_dir2_threshold_5": 0.4393938025604716,
      "scr_dir1_threshold_10": 0.4835166148755827,
      "scr_metric_threshold_10": 0.4835166148755827,
      "scr_dir2_threshold_10": 0.5454548738548681,
      "scr_dir1_threshold_20": 0.5000000818745071,
      "scr_metric_threshold_20": 0.5000000818745071,
      "scr_dir2_threshold_20": -1.8030309871976418,
      "scr_dir1_threshold_50": 0.5054945162911438,
      "scr_metric_threshold_50": 0.5054945162911438,
      "scr_dir2_threshold_50": -1.4393947056613587,
      "scr_dir1_threshold_100": 0.5989012113660811,
      "scr_metric_threshold_100": 0.5989012113660811,
      "scr_dir2_threshold_100": -1.4848486764153397,
      "scr_dir1_threshold_500": 0.12637362907278596,
      "scr_metric_threshold_500": 0.12637362907278596,
      "scr_dir2_threshold_500": -4.954546932346906
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.008546899691991681,
      "scr_metric_threshold_2": 0.30653260913191077,
      "scr_dir2_threshold_2": 0.30653260913191077,
      "scr_dir1_threshold_5": -0.5042737045667353,
      "scr_metric_threshold_5": 0.4572862334836728,
      "scr_dir2_threshold_5": 0.4572862334836728,
      "scr_dir1_threshold_10": -0.512820604258727,
      "scr_metric_threshold_10": 0.5226129238444337,
      "scr_dir2_threshold_10": 0.5226129238444337,
      "scr_dir1_threshold_20": -0.358974372036961,
      "scr_metric_threshold_20": 0.4974873197858067,
      "scr_dir2_threshold_20": 0.4974873197858067,
      "scr_dir1_threshold_50": -0.153846232221766,
      "scr_metric_threshold_50": 0.5226129238444337,
      "scr_dir2_threshold_50": 0.5226129238444337,
      "scr_dir1_threshold_100": -0.17948744073921996,
      "scr_metric_threshold_100": 0.5979897360203147,
      "scr_dir2_threshold_100": 0.5979897360203147,
      "scr_dir1_threshold_500": -0.3504274723449693,
      "scr_metric_threshold_500": 0.5226129238444337,
      "scr_dir2_threshold_500": 0.5226129238444337
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.14000003576279965,
      "scr_metric_threshold_2": 0.09392273198631267,
      "scr_dir2_threshold_2": 0.09392273198631267,
      "scr_dir1_threshold_5": 0.19000000596046662,
      "scr_metric_threshold_5": 0.1160222177070528,
      "scr_dir2_threshold_5": 0.1160222177070528,
      "scr_dir1_threshold_10": 0.20999975562086903,
      "scr_metric_threshold_10": 0.1657459782518852,
      "scr_dir2_threshold_10": 0.1657459782518852,
      "scr_dir1_threshold_20": 0.0900000655651327,
      "scr_metric_threshold_20": 0.2320444354141056,
      "scr_dir2_threshold_20": 0.2320444354141056,
      "scr_dir1_threshold_50": 0.17999953508360447,
      "scr_metric_threshold_50": 0.20994494969336547,
      "scr_dir2_threshold_50": 0.20994494969336547,
      "scr_dir1_threshold_100": 0.17999953508360447,
      "scr_metric_threshold_100": 0.2762430775482542,
      "scr_dir2_threshold_100": 0.2762430775482542,
      "scr_dir1_threshold_500": 0.17999953508360447,
      "scr_metric_threshold_500": 0.3314919565037704,
      "scr_dir2_threshold_500": 0.3314919565037704
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": -0.08333325054910777,
      "scr_metric_threshold_2": 0.11152405978102273,
      "scr_dir2_threshold_2": 0.11152405978102273,
      "scr_dir1_threshold_5": 0.05000034769374737,
      "scr_metric_threshold_5": 0.14869874637469696,
      "scr_dir2_threshold_5": 0.14869874637469696,
      "scr_dir1_threshold_10": 0.2000003973642827,
      "scr_metric_threshold_10": 0.12267655439056908,
      "scr_dir2_threshold_10": 0.12267655439056908,
      "scr_dir1_threshold_20": 0.13333359824285515,
      "scr_metric_threshold_20": 0.19330850323427218,
      "scr_dir2_threshold_20": 0.19330850323427218,
      "scr_dir1_threshold_50": 0.18333394593660252,
      "scr_metric_threshold_50": 0.2639404520779753,
      "scr_dir2_threshold_50": 0.2639404520779753,
      "scr_dir1_threshold_100": 0.2833336479133905,
      "scr_metric_threshold_100": 0.3048327845939051,
      "scr_dir2_threshold_100": 0.3048327845939051,
      "scr_dir1_threshold_500": 0.16666749450892232,
      "scr_metric_threshold_500": 0.24907053312478356,
      "scr_dir2_threshold_500": 0.24907053312478356
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": -0.00862109274842677,
      "scr_metric_threshold_2": 0.07741949625240678,
      "scr_dir2_threshold_2": 0.07741949625240678,
      "scr_dir1_threshold_5": 0.0862068168189925,
      "scr_metric_threshold_5": 0.109677523554405,
      "scr_dir2_threshold_5": 0.109677523554405,
      "scr_dir1_threshold_10": -0.03448282949422888,
      "scr_metric_threshold_10": 0.14193555085640322,
      "scr_dir2_threshold_10": 0.14193555085640322,
      "scr_dir1_threshold_20": 0.02586173674580211,
      "scr_metric_threshold_20": 0.14193555085640322,
      "scr_dir2_threshold_20": 0.14193555085640322,
      "scr_dir1_threshold_50": 0.10344797464952725,
      "scr_metric_threshold_50": 0.16774204960720546,
      "scr_dir2_threshold_50": 0.16774204960720546,
      "scr_dir1_threshold_100": 0.00862057891526737,
      "scr_metric_threshold_100": 0.019354970199606303,
      "scr_dir2_threshold_100": 0.019354970199606303,
      "scr_dir1_threshold_500": -0.07758623790372514,
      "scr_metric_threshold_500": -0.04516108440439013,
      "scr_dir2_threshold_500": -0.04516108440439013
    }
  ],
  "sae_bench_commit_hash": "8a839adff4a91e37c9c47577fdfb7eddafea55b6",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "pythia70m_sweep_standard_ctx128_0712_resid_post_layer_4_trainer_8_ae_pt",
  "sae_lens_version": "5.8.1",
  "sae_cfg_dict": {
    "model_name": "pythia-70m-deduped",
    "d_in": 512,
    "d_sae": 4096,
    "hook_layer": 4,
    "hook_name": "blocks.4.hook_resid_post",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "vanilla",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "float32",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": 200000000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}